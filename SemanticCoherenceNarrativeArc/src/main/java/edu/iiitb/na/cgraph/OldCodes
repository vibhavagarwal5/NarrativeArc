public static double getSemanticCoherence(String entity1, String entity2){
		//Manual Random Walks
		
		ArrayList<String> K1=extractKeyPhrases(entity1);
		ArrayList<String> K2= extractKeyPhrases(entity2);
		int numberOfKeywords = K1.size() + K2.size();
		
		//get the semantic context of Context of keyPhrases.
		Node nodes_1[] = null;
		nodes_1 = Primitives.getContext(K1);
		long graph_1[][] = Primitives.getSemanticContext(nodes_1);
		//Returns weight of the relationship between node[i]  and node[j] at graph[i][j]
		Node nodes_2[] = null;
		nodes_2 = Primitives.getContext(K2);
		long graph_2[][] = Primitives.getSemanticContext(nodes_2);

		//combine nodes and remove duplicates
		ArrayList<Node> nodesCombinedTemp = (new ArrayList<Node>(new LinkedHashSet<Node>(new ArrayList<Node>(Arrays.asList( ArrayUtils.addAll(nodes_1, nodes_2))))));
		int commonNode[] = new int[nodes_1.length + nodes_2.length];
		for(Node n : nodes_2)
		{
			int found = 0;
			for(int i = 0; i < nodesCombinedTemp.size(); i++)
			{
				if(nodesCombinedTemp.get(i).equals(n))
				{
					found = 1;
					commonNode[i] = 1;
				}
			}
			if(found == 0)
				nodesCombinedTemp.add(n);
		}
		Node nodesCombined[] = new Node[nodesCombinedTemp.size()];
		nodesCombined = nodesCombinedTemp.toArray(nodesCombined);
		String nodeNames[] = null;
		nodeNames = Primitives.getNodeNames(nodesCombined);
		
		//Semantic Coherence Context
		double transitionGraph[][] = Primitives.graphMerge(nodesCombined, graph_1, graph_2, nodes_1, nodes_2);
		int matrixSize = transitionGraph.length;
		
		//PrintFullMatrix(nodes_1, nodes_2, nodesCombined, graph_1, graph_2, transitionGraph, nodeNames);

		//Convert edge weights to probabilities
		double ProbabilityMatrix[][] = getProbabilityMatrix(transitionGraph);
		
		//Calculating Semantic Coherence Value using Random Walks
		double ScSum = 0.0;
		Random rand = new Random();
		for(int j = 0; j < Config.noOfRandomWalks; j++)
		{
			int commonNodesVisited = 0, totalNodesVisited = 0;
			int currentNode = rand.nextInt(matrixSize);
			for(int i = 0; i < Config.lengthOfRandomWalks; i++)
			{
				if(commonNode[currentNode] == 1)
					commonNodesVisited++;
				totalNodesVisited++;
				currentNode = getNextRandomNode(currentNode, ProbabilityMatrix, matrixSize);
			}
			//System.out.println(commonNodesVisited + " " + totalNodesVisited);
			ScSum += (double)commonNodesVisited / (double)totalNodesVisited;
		}
		return ScSum/Config.noOfRandomWalks;
	}
	
	public static double getSemanticCoherence(String entity1, String entity2){
		//Using Graph Multiply
		System.out.println("asdade new Semantic Coherence\nInputStrings:");
		System.out.println(entity1);
		System.out.println(entity2);
	
		ArrayList<String> K1=extractKeyPhrases(entity1);
		ArrayList<String> K2= extractKeyPhrases(entity2);
		int numberOfKeywords = K1.size() + K2.size();
		
		//get the semantic context of Context of keyPhrases.
		Node nodes_1[] = null;
		nodes_1 = Primitives.getContext(K1);
		long graph_1[][] = Primitives.getSemanticContext(nodes_1);
		//Returns weight of the relationship between node[i]  and node[j] at graph[i][j]
		Node nodes_2[] = null;
		nodes_2 = Primitives.getContext(K2);
		long graph_2[][] = Primitives.getSemanticContext(nodes_2);

		//combine nodes and remove duplicates
		Map<String, Integer> g1_nodes = Primitives.getMappingToNumbers(nodes_1);
		Map<String, Integer> g2_nodes = Primitives.getMappingToNumbers(nodes_2);
		
		System.out.println(g1_nodes.size() + " : " + g2_nodes.size());

		ArrayList<Pair> nodesCombinedTemp = Primitives.CombineNodesToPair(nodes_1, nodes_2);
		Pair nodesCombined[] = new Pair[nodesCombinedTemp.size()];
		nodesCombined = nodesCombinedTemp.toArray(nodesCombined);
		
		//Semantic Coherence Context - Graph Multiplication
		double transitionGraph[][] = Primitives.graphMultiplyNormalized(nodesCombined, graph_1, graph_2, g1_nodes, g2_nodes);
		int matrixSize = transitionGraph.length;
		
		//PrintFullMatrix(g1_nodes, g2_nodes, nodesCombined, graph_1, graph_2, transitionGraph, nodes_1, nodes_2);

		//Convert edge weights to probabilities
		double ProbabilityMatrix[][] = getProbabilityMatrix(transitionGraph);
		
		//Create Start Probability and Stop Probability
		double startProbabilityVector[] = new double[matrixSize];
		double stopProbabilityVector[] = new double[matrixSize];
		int countNumberOfStartNodes = 0;
		for(int i = 0; i < matrixSize; i++)
		{
			stopProbabilityVector[i] = 1.0/(double)matrixSize;
			if(K1.contains(nodesCombined[i].first))
				countNumberOfStartNodes++;
			if(K2.contains(nodesCombined[i].first))
				countNumberOfStartNodes++;
		}
		double divisor = countNumberOfStartNodes+(Config.LAMBDA*countNumberOfStartNodes);
		for(int i = 0; i < matrixSize; i++)
		{
			if(K1.contains(nodesCombined[i].first) && K2.contains(nodesCombined[i].second))
				startProbabilityVector[i] = (Config.LAMBDA+2.0)/divisor;
			else if(K1.contains(nodesCombined[i].first) || K2.contains(nodesCombined[i].second))
				startProbabilityVector[i] = (Config.LAMBDA+1.0)/divisor;
			else
				startProbabilityVector[i] = Config.LAMBDA;
		}
		
		//Calculating Semantic Coherence Value
		double SC = 0.0;
		double tempTransitionGraph[][] = new double[matrixSize][matrixSize]; //Stores the M^k value in the summation.
		for(int i = 0; i < matrixSize; i++)
			for(int j = 0; j < matrixSize; j++)
				tempTransitionGraph[i][j] = ProbabilityMatrix[i][j];
		for(int i = 0; i < Config.noOfIterationsForSC; i++)
		{
			SC += (Config.LAMBDA*(Primitives.MatMult(stopProbabilityVector, Primitives.MatMult(tempTransitionGraph, startProbabilityVector))));
			tempTransitionGraph = Primitives.MatMult(tempTransitionGraph, ProbabilityMatrix);
		}
		
		return SC;
	}
	
	
	
	
	public static double[] OldgetSemanticCoherence(String entity1, String entity2){
		//Using Graph Merge
		System.out.println("new Semantic Coherence\nInputStrings:");
		System.out.println(entity1);
		System.out.println(entity2);

		ArrayList<String> K1=extractKeyPhrases(entity1);
		ArrayList<String> K2= extractKeyPhrases(entity2);
		int numberOfKeywords = K1.size() + K2.size();
		
		//get the semantic context of Context of keyPhrases.
		Node nodes_1[] = null;
		nodes_1 = Primitives.getContext(K1);
		long graph_1[][] = Primitives.getSemanticContext(nodes_1);
		//Returns weight of the relationship between node[i]  and node[j] at graph[i][j]
		Node nodes_2[] = null;
		nodes_2 = Primitives.getContext(K2);
		long graph_2[][] = Primitives.getSemanticContext(nodes_2);
		
		//combine nodes and remove duplicates
		ArrayList<Node> nodesCombinedTemp = (new ArrayList<Node>(new LinkedHashSet<Node>(new ArrayList<Node>(Arrays.asList( ArrayUtils.addAll(nodes_1, nodes_2))))));
		Node nodesCombined[] = new Node[nodesCombinedTemp.size()];
		nodesCombined = nodesCombinedTemp.toArray(nodesCombined);
		String nodeNames[] = null;
		nodeNames = Primitives.getNodeNames(nodesCombined);
		
		//Semantic Coherence Context
		double transitionGraph[][] = Primitives.graphMerge(nodesCombined, graph_1, graph_2, nodes_1, nodes_2);
		int matrixSize = transitionGraph.length;
		
		System.out.println(matrixSize);
		
		//PrintFullMatrix(nodes_1, nodes_2, nodesCombined, graph_1, graph_2, transitionGraph, nodeNames);

		//Convert edge weights to probabilities
		double ProbabilityMatrix[][] = getProbabilityMatrix(transitionGraph);
		
		//Create Start Probability and Stop Probability
		double startProbabilityVector[] = new double[matrixSize];
		double answerVector[] = new double[matrixSize];
		for(int i = 0; i < matrixSize; i++)
		{
			answerVector[i] = 0;
			if(K1.contains(nodeNames[i]) || K2.contains(nodeNames[i]))
				startProbabilityVector[i] = (Config.DELTA+1.0)/((Config.DELTA*numberOfKeywords) + numberOfKeywords);
			else
				startProbabilityVector[i] =  (Config.DELTA)/((Config.DELTA*numberOfKeywords) + numberOfKeywords);
		}
		
		System.out.println("Goes to Semantic Coherence value");
		
		//Calculating Semantic Coherence Value
		double SC = 0.0;
		double tempTransitionGraph[][] = new double[matrixSize][matrixSize]; //Stores the M^k value in the summation.
		for(int i = 0; i < matrixSize; i++)
			for(int j = 0; j < matrixSize; j++)
				tempTransitionGraph[i][j] = ProbabilityMatrix[i][j];
		for(int i = 0; i < Config.noOfIterationsForSC; i++)
		{
			System.out.println(i);
			answerVector = Primitives.VectorAdd(answerVector, Primitives.MatMult(startProbabilityVector, tempTransitionGraph));
			tempTransitionGraph = Primitives.MatMult(tempTransitionGraph, ProbabilityMatrix);
		}
		
		
		return answerVector;
	}