{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import util\n",
    "import ast\n",
    "import pickle\n",
    "import math\n",
    "from scipy.spatial.distance import cosine\n",
    "import subprocess\n",
    "import random\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "from numpy import linalg as LA\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from keras.models import model_from_json\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Solve the Linear equation Solve the Linear equation'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = util.get_processed_data(\"./../data/collections_math.csv\", False)\n",
    "collections = util.get_collections(df)\n",
    "df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['collection_id','sequence_id'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.ldamodel.LdaModel\n",
    "fileObject = open('./../PickelFiles/lda_science_dictionary.model','rb')  \n",
    "dictionary = pickle.load(fileObject)\n",
    "ldamodel = lda.load('./../PickelFiles/lda_25_sc.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model reconstruction from JSON file\n",
    "with open('./../Final_Data/Validator_windowsize_3_archi.json', 'r') as f:\n",
    "    validator = model_from_json(f.read())\n",
    "\n",
    "# Load weights into the new model\n",
    "validator.load_weights('./../Final_Data/Validator_windowsize_3_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27754 entries, 3 to 27749\n",
      "Data columns (total 6 columns):\n",
      "collection_id    27754 non-null object\n",
      "sequence_id      27754 non-null int64\n",
      "resource_id      27754 non-null object\n",
      "title            27754 non-null object\n",
      "description      27754 non-null object\n",
      "text             27754 non-null object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing words with length 1 since tfidf does not recognize them\n",
    "\n",
    "for col in collections:\n",
    "    lrs = []\n",
    "    for i,text in enumerate(col[\"texts\"]):\n",
    "        new_text = \"\"\n",
    "        for word in text.split():\n",
    "            if len(word)>2:\n",
    "                new_text+=word+\" \"\n",
    "        if new_text.strip()!=\"\":\n",
    "            lrs.append(new_text.strip().lower())\n",
    "    col[\"texts\"] = lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading doc2vec ad word2vec models and functions for return embeddingsfor a paticular text\n",
    "\n",
    "d2v= Doc2Vec.load(\"./../doc2vec_100dim.model\")\n",
    "\n",
    "def document_embeddings(doc):\n",
    "    test_data = word_tokenize(doc.lower())\n",
    "    return d2v.infer_vector(test_data)        \n",
    "\n",
    "\n",
    "word2vec = Word2Vec.load('./../Word2Vec_100dim.bin')\n",
    "\n",
    "def Word2doc(doc):\n",
    "    words=doc.split()\n",
    "    emb=np.zeros(100)\n",
    "    for word in words:\n",
    "        if(word in word2vec.wv.vocab):\n",
    "            emb = np.add(emb,word2vec[word])\n",
    "    if(len(doc)!=0) :       \n",
    "        return emb/len(words)\n",
    "    else:\n",
    "        return(np.zeros(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading svm model\n",
    "\n",
    "pickle_in = open(\"./../data/svm_model_cosine_embed_novelty_SC.sav\",\"rb\")\n",
    "svm_fun = pickle.load(pickle_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate cosin similarity for two embedding\n",
    "\n",
    "def cosin(v1,v2):\n",
    "    if(LA.norm(v1)!=0 and LA.norm(v2)!=0):\n",
    "        return (np.dot(np.array(v1),np.array(v2))/(LA.norm(v1) * LA.norm(v2)))\n",
    "    else:\n",
    "        return 1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# java -jar NoveltySemanticCoherence.jar  SinglePair\n",
    "\n",
    "def getNoveltySC(text1,text2):\n",
    "    cmd =['java','-jar','NoveltySemanticCoherence.jar','SinglePair',text1,text2]\n",
    "    subprocess.call(cmd)\n",
    "    f = open(\"./data/pairwise/singlepairwise\", \"r\")\n",
    "    sc =float(f.readline()) \n",
    "    nv = float(f.readline())\n",
    "    return sc,nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ldamodel.get_document_topics([\"solve\"],per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to predict similarity between two text using svm model\n",
    "\n",
    "def text_similarity_svm(text1, text2):\n",
    "    \n",
    "    dv1 = document_embeddings(text1)\n",
    "    dv2 = document_embeddings(text2)\n",
    "    \n",
    "    wd1 = Word2doc(text1)\n",
    "    wd2 = Word2doc(text1)\n",
    "    \n",
    "    ds = cosin(dv1,dv2)\n",
    "    ws = cosin(wd1,wd2)\n",
    "\n",
    "    clean_matrix1 = clean(text1).split()\n",
    "    clean_matrix2 = clean(text2).split() \n",
    "\n",
    "    clean_matrix1 = dictionary.doc2bow(clean_matrix1)  \n",
    "    clean_matrix2 = dictionary.doc2bow(clean_matrix2) \n",
    "    \n",
    "    lda_1 = ldamodel.get_document_topics(clean_matrix1,per_word_topics=True)[0] \n",
    "    lda_2 = ldamodel.get_document_topics(clean_matrix2,per_word_topics=True)[0] \n",
    "\n",
    "#     print(lda_1)\n",
    "#     lda_1 = clean_matrix1.apply(lambda x: ldamodel.get_document_topics(x,per_word_topics=True)[0])\n",
    "#     lda_2 = clean_matrix1.apply(lambda x: ldamodel.get_document_topics(x,per_word_topics=True)[0])\n",
    "\n",
    "    a_list=[]\n",
    "    b_list=[]\n",
    "    for i,j in lda_1:\n",
    "        a_list.append(j)\n",
    "\n",
    "    for i,j in lda_2:\n",
    "        b_list.append(j)\n",
    "    \n",
    "    a_list=np.array(a_list)\n",
    "    b_list=np.array(b_list)\n",
    "\n",
    "    kl = np.sum(np.where(a_list!=0,a_list*np.log(a_list/b_list),0))    \n",
    "    sc,nv =getNoveltySC(text1,text2)\n",
    "    \n",
    "    data=[]\n",
    "    \n",
    "    data.append(ds)\n",
    "    data.append(ws)\n",
    "    data.append(sc)\n",
    "    data.append(nv)\n",
    "    data.append(kl)\n",
    "        \n",
    "    similarity = svm_fun.predict_proba(np.array(data).reshape(1,5))[0][1]\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    dv1 = document_embeddings(text)\n",
    "    wd1 = Word2doc(text)\n",
    "    clean_matrix1 = clean(text).split()\n",
    "    clean_matrix1 = dictionary.doc2bow(clean_matrix1)      \n",
    "    lda = ldamodel.get_document_topics(clean_matrix1,per_word_topics=True)[0] \n",
    "#     print(type(wd1))\n",
    "    data = []\n",
    "    data += list(wd1)\n",
    "    data += list(dv1)\n",
    "    for j in range(0,20):\n",
    "            data += [lda[j][1]]\n",
    "    return data                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validator_score(a,b,c):\n",
    "    print(\"entered validator checking\")\n",
    "    temp=[]\n",
    "    frame=[]\n",
    "    data1=get_embedding(a)\n",
    "    data2=get_embedding(b)    \n",
    "    data3=get_embedding(c)    \n",
    "    \n",
    "    temp.append(data1)\n",
    "    temp.append(data2)\n",
    "    temp.append(data3)\n",
    "    frame.append(temp)\n",
    "    \n",
    "    score = validator.predict(np.reshape(frame,(1,3,220)))\n",
    "    print(\"left validator checking\")\n",
    "    return score[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>resource_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0008d66a-753f-4639-8634-81bb3abb3269</td>\n",
       "      <td>1</td>\n",
       "      <td>231eb4ad-d0e8-4e94-a552-f8bd2358a47a</td>\n",
       "      <td>Solve the linear equation: _______</td>\n",
       "      <td>Solve the linear equation:            [1/2] ...</td>\n",
       "      <td>Solve the linear equation Solve the linear equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0008d66a-753f-4639-8634-81bb3abb3269</td>\n",
       "      <td>2</td>\n",
       "      <td>0b248202-12a9-405b-acd1-4ab8250e4198</td>\n",
       "      <td>If , then _______</td>\n",
       "      <td>If      , then      [1/5]. &amp;nbsp;Please writ...</td>\n",
       "      <td>If then If then nbsp Please write your answer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008d66a-753f-4639-8634-81bb3abb3269</td>\n",
       "      <td>3</td>\n",
       "      <td>2ee6f80f-0851-4cfa-b4bf-2655e9c46ab7</td>\n",
       "      <td>Solve the Linear equation: _______</td>\n",
       "      <td>Solve the Linear equation:            [2]</td>\n",
       "      <td>Solve the Linear equation Solve the Linear equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0008d66a-753f-4639-8634-81bb3abb3269</td>\n",
       "      <td>4</td>\n",
       "      <td>81c6995c-dd95-418e-a8c4-c22d8ccd32e9</td>\n",
       "      <td>Solve the linear equation: _______</td>\n",
       "      <td>Solve the linear equation:            [-18]</td>\n",
       "      <td>Solve the linear equation Solve the linear equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008d66a-753f-4639-8634-81bb3abb3269</td>\n",
       "      <td>5</td>\n",
       "      <td>15a464a4-a2d8-41dd-b00e-ff7fea0aa720</td>\n",
       "      <td>If , then _______</td>\n",
       "      <td>If      , then      [-4]</td>\n",
       "      <td>If then If then</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          collection_id  sequence_id  \\\n",
       "3  0008d66a-753f-4639-8634-81bb3abb3269            1   \n",
       "2  0008d66a-753f-4639-8634-81bb3abb3269            2   \n",
       "0  0008d66a-753f-4639-8634-81bb3abb3269            3   \n",
       "4  0008d66a-753f-4639-8634-81bb3abb3269            4   \n",
       "1  0008d66a-753f-4639-8634-81bb3abb3269            5   \n",
       "\n",
       "                            resource_id                               title  \\\n",
       "3  231eb4ad-d0e8-4e94-a552-f8bd2358a47a  Solve the linear equation: _______   \n",
       "2  0b248202-12a9-405b-acd1-4ab8250e4198                   If , then _______   \n",
       "0  2ee6f80f-0851-4cfa-b4bf-2655e9c46ab7  Solve the Linear equation: _______   \n",
       "4  81c6995c-dd95-418e-a8c4-c22d8ccd32e9  Solve the linear equation: _______   \n",
       "1  15a464a4-a2d8-41dd-b00e-ff7fea0aa720                   If , then _______   \n",
       "\n",
       "                                         description  \\\n",
       "3    Solve the linear equation:            [1/2] ...   \n",
       "2    If      , then      [1/5]. &nbsp;Please writ...   \n",
       "0         Solve the Linear equation:            [2]    \n",
       "4       Solve the linear equation:            [-18]    \n",
       "1                          If      , then      [-4]    \n",
       "\n",
       "                                                text  \n",
       "3  Solve the linear equation Solve the linear equ...  \n",
       "2  If then If then nbsp Please write your answer ...  \n",
       "0  Solve the Linear equation Solve the Linear equ...  \n",
       "4  Solve the linear equation Solve the linear equ...  \n",
       "1                                    If then If then  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll=df.collection_id.values\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get mean text similarity score of given corpus(data)\n",
    "\n",
    "def get_mean_score_pair(data, score_function):\n",
    "    score_sum = 0.0\n",
    "    for lr1, lr2 in data:\n",
    "        score_sum += score_function(lr1, lr2)\n",
    "    return score_sum/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all learning resources \n",
    "\n",
    "lr_list = []\n",
    "col_list = [] \n",
    "count = 0\n",
    "for col in collections:\n",
    "    if(len(col[\"texts\"])>6): col_list.append(col[\"id\"])\n",
    "    for lr in col[\"texts\"]:\n",
    "        if(len(lr)>0):\n",
    "            lr_list.append(lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbourhood_text(text,threshold):\n",
    "    cos_sim = []\n",
    "    return_list = []\n",
    "    for i in lr_list:\n",
    "            cs = cosin(Word2doc(text),Word2doc(i)) \n",
    "            cos_sim.append(cs)\n",
    "            if((threshold -0.1)<cs and cs<(threshold +0.1) and i not in return_list):\n",
    "                return_list.append(i)\n",
    "    return return_list[:min(5,len(return_list))]                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate next learning learning resource given starting and list of learning resources to select and \n",
    "# minimum similarity between them.\n",
    "\n",
    "def get_next_lr(given_lr, lr_list, target_score, collection, score_function):\n",
    "    next_lr = \"\"\n",
    "    score_diff = 0\n",
    "    for lr in lr_list:\n",
    "        if lr not in collection:\n",
    "            score = score_function(given_lr, lr)\n",
    "            if (score - target_score) > score_diff:\n",
    "                score_diff = (score - target_score)\n",
    "                next_lr = lr\n",
    "    return next_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a collection/pathway \n",
    "\n",
    "def create_collection(collection_size, start_lr, target_score, score_function):\n",
    "    lr_list = neighbourhood_text(start_lr,0.7)\n",
    "    collection = [start_lr]\n",
    "    lr = start_lr\n",
    "    if(start_lr in lr_list): \n",
    "        lr_list.remove(start_lr)\n",
    "    for i in range(collection_size - 1):\n",
    "        next_lr = get_next_lr(lr, lr_list, target_score, collection, score_function)\n",
    "        collection.append(next_lr)\n",
    "        old = lr\n",
    "        lr = next_lr\n",
    "        lr_list = neighbourhood_text(lr,0.7)   \n",
    "\n",
    "        if(i>=2 & len(collection)>=2):\n",
    "            print(\"length of collection is \",len(collection))\n",
    "            print(\"value of i is \",i)\n",
    "            sco = get_validator_score(collection[i-2],collection[i-1],collection[i])\n",
    "            if(sco < 0.5 ):\n",
    "                i=i-1\n",
    "                collection.pop()\n",
    "                lr = old\n",
    "                \n",
    "        if(next_lr in lr_list):\n",
    "            lr_list.remove(next_lr)\n",
    "        \n",
    "        print(next_lr)\n",
    "            \n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all possible pairs of consecutive resources\n",
    "\n",
    "lr_pairs = []\n",
    "\n",
    "for col in collections:\n",
    "    for i in range(len(col[\"texts\"]) -1):\n",
    "        lr1 = col[\"texts\"][i]\n",
    "        lr2 = col[\"texts\"][i+1]\n",
    "        lr_pairs.append([lr1, lr2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_cosine = []\n",
    "\n",
    "# for pair in lr_pairs:\n",
    "#     wv1=Word2doc(pair[0])\n",
    "#     wv2=Word2doc(pair[1])\n",
    "#     all_cosine.append(cosin(wv1,wv2))\n",
    "\n",
    "# calculating mean of all consecutive learning resources\n",
    "# mean = get_mean_score_pair(lr_pairs, text_similarity_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(all_cosine,bins=30)\n",
    "# plt.ylabel('Cosine Similarity');    \n",
    "# plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortSecond(val): \n",
    "    return val[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_collection(seed_val,threshold):\n",
    "    random.seed(seed_val)\n",
    "    start_lr = lr_list[random.randint(0,len(lr_list))]\n",
    "    print(start_lr)\n",
    "\n",
    "#     temp_list = [] \n",
    "#     wd1 = Word2doc(start_lr)\n",
    "#     for i in lr_list:\n",
    "#         wd2 = Word2doc(i)\n",
    "#         ws = cosin(wd1,wd2)\n",
    "#         temp_list.append([i,ws])\n",
    "#     temp_list.sort(key = sortSecond ,reverse = True)\n",
    "\n",
    "#     hist = []\n",
    "#     for i in temp_list:\n",
    "#         hist.append(i[1])\n",
    "#     plt.hist(hist,bins=60)\n",
    "#     plt.ylabel('Cosine Similarity');    \n",
    "#     plt.show()    \n",
    "    \n",
    "#     neig_list = [] \n",
    "#     for i in range(0,min(10,len(temp_list))):\n",
    "#         if(temp_list[i][1]!=1 and temp_list[i][0] not in neig_list):\n",
    "#             neig_list.append(temp_list[i][0])\n",
    "    \n",
    "    new_collection = create_collection(8, start_lr, threshold, text_similarity_svm)\n",
    "\n",
    "    # print(new_collection)\n",
    "    f = open(\"./../Final_Data/Genetrated collections/collection_KL_Validator_\"+str(seed_val)+\"_\"+str(threshold),\"w\")\n",
    "    for i in new_collection:\n",
    "        f.write(i+\"\\n\")\n",
    "        f.write(\"--------------------------------------------------------------\\n\")\n",
    "        print(i)\n",
    "        print(\"----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generating_collection(2019,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there relationship between moisture content when straight line provides reasonable summary the relationship between two numerical variables say thatthe two variables are linearly related that there linear relationship between the two variables take look the scatter plots below and answer the questions that follow there relationship between moisture content and frying time the data points look scattered there relationship between moisture content and frying time does the relationship look linear\n",
      "how can the graph how can the graph horizontally translated positive negative\n",
      "draw graph made function the board draw graph made function the board labeled and show how translate right orleft units using the equation\n",
      "the effects these transformations the graph there nothing special about using the function students did this lesson the effects these transformations the graph function hold true for all functions\n",
      "\n",
      "length of collection is  6\n",
      "value of i is  4\n",
      "entered validator checking\n",
      "left validator checking\n",
      "\n",
      "length of collection is  6\n",
      "value of i is  5\n",
      "entered validator checking\n",
      "left validator checking\n",
      "\n",
      "length of collection is  6\n",
      "value of i is  6\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-470a30cfd6f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerating_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2016\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-110-1503c4c3749e>\u001b[0m in \u001b[0;36mgenerating_collection\u001b[0;34m(seed_val, threshold)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#             neig_list.append(temp_list[i][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mnew_collection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_similarity_svm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# print(new_collection)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-ebde40e81688>\u001b[0m in \u001b[0;36mcreate_collection\u001b[0;34m(collection_size, start_lr, target_score, score_function)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"length of collection is \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value of i is \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0msco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_validator_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msco\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "generating_collection(2016,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generating_collection(1,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
