{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  importing modules\n",
    "\n",
    "# %load LDA-Copy1.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import util\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the dataframe\n",
    "df = util.get_processed_data(\"./data/collections_all_science_out-temp.csv\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the cleaning function to remove stop words and lemmatize them.\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing junk words from summarization and creating the dictionary to be used in LDA\n",
    "df.Summarisation.replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)\n",
    "df['clean'] = df.Summarisation.apply(clean)\n",
    "df.clean = df.clean.apply(lambda x: x.split())\n",
    "dictionary = gensim.corpora.Dictionary(df.clean)\n",
    "df['clean_matrix'] = df.clean.apply(lambda x: dictionary.doc2bow(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building LDA model\n",
    "lda = gensim.models.ldamodel.LdaModel\n",
    "np.random.seed(1)\n",
    "ldamodel = lda(\n",
    "    df.clean_matrix, \n",
    "    num_topics=20, \n",
    "    id2word = dictionary, \n",
    "    passes=100,\n",
    "    minimum_probability=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in ldamodel.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the LDA\n",
    "vis_data = pyLDAvis.gensim.prepare(ldamodel,df.clean_matrix,dictionary)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "ldamodel.save('./lda_25_sc/lda_25_sc.model')\n",
    "ldamodel = ldamodel.load('./lda_25_sc/lda_25_sc.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column for the LDA distribution pertaining to each LR\n",
    "df['lda_topics'] = df.clean_matrix.apply(lambda x: ldamodel.get_document_topics(x,per_word_topics=True)[0])\n",
    "df['lda_topics'] = df.lda_topics.apply(lambda x : [b for _ ,b in x ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lda_topics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "df.to_csv(\"./data/collections_all_science_out-temp_lda.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
