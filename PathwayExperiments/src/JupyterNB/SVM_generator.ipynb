{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import util\n",
    "import ast\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import math\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "from numpy import linalg as LA\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier as ada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Final_Data/all_pairs_science.csv\")\n",
    "df = pd.read_csv(\"./Final_Data/all_pairs_science_sc_nv.csv\")\n",
    "    \n",
    "data[\"SC_score\"] = df [\"SC_score\"]\n",
    "data[\"Novelty_score\"] = df [\"Novelty_score\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.lda_topicss1 =data.lda_topicss1.apply(lambda x: ast.literal_eval(x))\n",
    "data.lda_topicss2 =data.lda_topicss2.apply(lambda x: ast.literal_eval(x))\n",
    "# type(data.lda_topicss1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  generating the target variable\n",
    "# data[\"vaild_resource\"] = data[\"collection_id1\"] == data['collection_id2']        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading doc2vec and word2vec models and function to return doc embedding\n",
    "model1= Doc2Vec.load(\"./Final_Data/doc2vec_100dim_science.model\")\n",
    "# model2 =Doc2Vec.load(\"doc2vec_50dim.model\")\n",
    "\n",
    "def document_embeddings(doc,Embedding_size=100):\n",
    "    test_data = word_tokenize(doc.lower())\n",
    "    return model1.infer_vector(test_data)            \n",
    "#     if(Embedding_size==100):\n",
    "#         return model1.infer_vector(test_data)        \n",
    "#     elif (Embedding_size == 50):\n",
    "#         return model2.infer_vector(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating doc embedding for pairwise resources\n",
    "data[\"embeddings_text1\"] = data.Summarizations1.apply(lambda x: document_embeddings(x))\n",
    "data[\"embeddings_text2\"] = data.Summarizations2.apply(lambda x: document_embeddings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading word2vec and function to retuen word embeddings\n",
    "\n",
    "word2vec = Word2Vec.load('./Final_Data/Word2Vec_100dim_science')\n",
    "\n",
    "def Word2doc(x):\n",
    "    words=x.split()\n",
    "    emb=np.zeros(100)\n",
    "    for word in words:\n",
    "        if(word in word2vec.wv.vocab):\n",
    "            emb = np.add(emb,word2vec[word])\n",
    "    return emb/len(words)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating word embedding for pairwise resources\n",
    "\n",
    "data[\"word_emb1\"]=data.Summarizations1.apply(lambda x :Word2doc(x))\n",
    "data[\"word_emb2\"]=data.Summarizations2.apply(lambda x :Word2doc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing cosine similarity between pairs of document embedding and word embeddings\n",
    "data[\"doc_cosine\"] = 0\n",
    "data[\"word_cosine\"] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to calcualte cosine similarity between pairs of document embedding and word embeddings\n",
    "\n",
    "def cosine_angle_word(x):\n",
    "    if(LA.norm(x[\"word_emb1\"])!=0 and LA.norm(x[\"word_emb2\"])!=0):\n",
    "        return (np.dot(np.array(x[\"word_emb1\"]),np.array(x[\"word_emb2\"]))/(LA.norm(x[\"word_emb1\"]) * LA.norm(x[\"word_emb2\"])))\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def cosine_angle_doc(x):\n",
    "    if(LA.norm(x[\"embeddings_text2\"])!=0 and LA.norm(x[\"embeddings_text1\"])!=0):\n",
    "        return (np.dot(np.array(x[\"embeddings_text1\"]),np.array(x[\"embeddings_text2\"]))/(LA.norm(x[\"embeddings_text1\"]) * LA.norm(x[\"embeddings_text2\"])))\n",
    "    else:\n",
    "        return 1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualting cosine similarity between pairs of document embedding and word embeddings\n",
    "\n",
    "data[\"doc_cosine\"]= data.apply(cosine_angle_doc,axis=1)\n",
    "data[\"word_cosine\"]= data.apply(cosine_angle_word,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the target table \n",
    "\n",
    "# def encoding(boolean):\n",
    "#     if(boolean):\n",
    "#         return 1\n",
    "#     return 0\n",
    "\n",
    "# data.vaild_resource = data.vaild_resource.apply(lambda x:encoding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splitting document embeddings to send as input for svm\n",
    "\n",
    "# columns=[\"docEmb1_\" + str(i) for i in range(1,101)]\n",
    "# data[columns] = pd.DataFrame(data.embeddings_text1.values.tolist(), index= data.index)\n",
    "\n",
    "\n",
    "# columns=[\"docEmb2_\" + str(i) for i in range(1,101)]\n",
    "# data[columns] = pd.DataFrame(data.embeddings_text2.values.tolist(), index= data.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splitting word embeddings to send as input for svm\n",
    "\n",
    "# columns=[\"wordEmb1_\" + str(i) for i in range(1,101)]\n",
    "# data[columns] = pd.DataFrame(data.word_emb1.values.tolist(), index= data.index)\n",
    "\n",
    "# columns=[\"wordEmb2_\" + str(i) for i in range(1,101)]\n",
    "# data[columns] = pd.DataFrame(data.word_emb2.values.tolist(), index= data.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda = gensim.models.ldamodel.LdaModel\n",
    "# fileObject = open('./PickelFiles/lda_dictionary.model','rb')  \n",
    "# dictionary = pickle.load(fileObject)\n",
    "# ldamodel = lda.load('./PickelFiles/lda_25_sc.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop = set(stopwords.words('english'))\n",
    "# exclude = set(string.punctuation) \n",
    "# lemma = WordNetLemmatizer()\n",
    "# def clean(doc):\n",
    "#     stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "#     punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "#     normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "#     return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"clean1\"]=data.text1.apply(lambda x: clean(x))\n",
    "# data[\"clean2\"]=data.text2.apply(lambda x: clean(x))\n",
    "# data.clean1= data.clean1.apply(lambda x: x.split())\n",
    "# data.clean2 = data.clean2.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['clean_matrix1'] = data.clean1.apply(lambda x: dictionary.doc2bow(x))\n",
    "# data['clean_matrix2'] = data.clean2.apply(lambda x: dictionary.doc2bow(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['lda_topic1'] = data.clean_matrix1.apply(lambda x: ldamodel.get_document_topics(x,per_word_topics=True)[0])\n",
    "# data['lda_topic2'] = data.clean_matrix2.apply(lambda x: ldamodel.get_document_topics(x,per_word_topics=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_Divergence(x):\n",
    "    a = x[\"lda_topicss1\"]\n",
    "    b = x[\"lda_topicss2\"]\n",
    "#     a_list=[]\n",
    "#     b_list=[]\n",
    "#     for i,j in a:\n",
    "#         a_list.append(j)\n",
    "\n",
    "#     for i,j in b:\n",
    "#         b_list.append(j)\n",
    "    \n",
    "    a_list=np.array(a)\n",
    "    b_list=np.array(b)\n",
    "    return np.sum(np.where(a_list!=0,a_list*np.log(a_list/b_list),0))\n",
    "\n",
    "data[\"kl_divergence\"]= 0\n",
    "data[\"kl_divergence\"]= data.apply(KL_Divergence,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_to_use to train svm\n",
    " \n",
    "features_to_use=[]\n",
    "\n",
    "# for i in range(1,101):\n",
    "#     features_to_use.append(\"docEmb1_\"+str(i))\n",
    "#     features_to_use.append(\"docEmb2_\"+str(i))    \n",
    "#     features_to_use.append(\"wordEmb1_\"+str(i))    \n",
    "#     features_to_use.append(\"wordEmb2_\"+str(i))\n",
    "\n",
    "features_to_use.append(\"doc_cosine\")    \n",
    "features_to_use.append(\"word_cosine\")    \n",
    "features_to_use.append(\"SC_score\")  \n",
    "features_to_use.append(\"Novelty_score\")\n",
    "features_to_use.append(\"kl_divergence\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting train and test data\n",
    "Finaldata = shuffle(data,random_state = 2019)\n",
    "\n",
    "X = Finaldata[features_to_use]\n",
    "y = Finaldata[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finaldata.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of Train :\",len(X_train))\n",
    "print(\"Size of Test :\",len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training svm on training data\n",
    "clf =  OneVsRestClassifier(svm.SVC(probability=True,verbose = True),n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting probability on test data\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predcition on test data\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "array = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"01\"],\n",
    "                  columns = [i for i in \"01\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True,fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on test data\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logloss on test data\n",
    "log_loss(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the svm model\n",
    "filename = './Final_Data/Science_SVM_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the data file\n",
    "Finaldata.to_csv(\"./Final_Data/Science_SVM_Data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loading svm model\n",
    "# pickle_in = open(\"./data/Science_SVM_model.sav\",\"rb\")\n",
    "# clf = pickle.load(pickle_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
