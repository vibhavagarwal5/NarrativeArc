{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses Glove embeddings for words.\n",
    "# Hidden layers of LSTMs for word level feed into another LSTM whose last hidden layer is used to classify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import util\n",
    "import random\n",
    "import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "WORD_HIDDEN_DIM = 30\n",
    "SENT_HIDDEN_DIM = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = embeddings.load_glove()\n",
    "\n",
    "# language_model = embeddings.load_local_word2vec()\n",
    "# text = util.get_alphanumeral(collections[0][\"texts\"][0])\n",
    "# embeddings.get_doc_embedding(model, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = util.get_processed_data(\"./data/collections_math.csv\", True)\n",
    "collections = util.get_collections(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>resource_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008d66a-753f-4639-8634-81bb3abb3269</td>\n",
       "      <td>3</td>\n",
       "      <td>2ee6f80f-0851-4cfa-b4bf-2655e9c46ab7</td>\n",
       "      <td>Solve the Linear equation: _______</td>\n",
       "      <td>Solve the Linear equation:            [2]</td>\n",
       "      <td>Solve Linear equation Solve Linear equation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008d66a-753f-4639-8634-81bb3abb3269</td>\n",
       "      <td>4</td>\n",
       "      <td>81c6995c-dd95-418e-a8c4-c22d8ccd32e9</td>\n",
       "      <td>Solve the linear equation: _______</td>\n",
       "      <td>Solve the linear equation:            [-18]</td>\n",
       "      <td>Solve linear equation Solve linear equation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0008d66a-753f-4639-8634-81bb3abb3269</td>\n",
       "      <td>1</td>\n",
       "      <td>231eb4ad-d0e8-4e94-a552-f8bd2358a47a</td>\n",
       "      <td>Solve the linear equation: _______</td>\n",
       "      <td>Solve the linear equation:            [1/2] ...</td>\n",
       "      <td>Solve linear equation Solve linear equation Pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0008d66a-753f-4639-8634-81bb3abb3269</td>\n",
       "      <td>2</td>\n",
       "      <td>0b248202-12a9-405b-acd1-4ab8250e4198</td>\n",
       "      <td>If , then _______</td>\n",
       "      <td>If      , then      [1/5]. &amp;nbsp;Please writ...</td>\n",
       "      <td>nbsp Please write answer fraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bf2c6-8ede-478a-9b8b-d7750488cb1b</td>\n",
       "      <td>1</td>\n",
       "      <td>1b922fae-619f-4f52-9551-663b3206e4e5</td>\n",
       "      <td>Lesson 11</td>\n",
       "      <td>I'll say an addition or subtraction sentence. ...</td>\n",
       "      <td>Lesson say addition subtraction sentence say a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          collection_id  sequence_id  \\\n",
       "0  0008d66a-753f-4639-8634-81bb3abb3269            3   \n",
       "1  0008d66a-753f-4639-8634-81bb3abb3269            4   \n",
       "2  0008d66a-753f-4639-8634-81bb3abb3269            1   \n",
       "3  0008d66a-753f-4639-8634-81bb3abb3269            2   \n",
       "4  001bf2c6-8ede-478a-9b8b-d7750488cb1b            1   \n",
       "\n",
       "                            resource_id                               title  \\\n",
       "0  2ee6f80f-0851-4cfa-b4bf-2655e9c46ab7  Solve the Linear equation: _______   \n",
       "1  81c6995c-dd95-418e-a8c4-c22d8ccd32e9  Solve the linear equation: _______   \n",
       "2  231eb4ad-d0e8-4e94-a552-f8bd2358a47a  Solve the linear equation: _______   \n",
       "3  0b248202-12a9-405b-acd1-4ab8250e4198                   If , then _______   \n",
       "4  1b922fae-619f-4f52-9551-663b3206e4e5                           Lesson 11   \n",
       "\n",
       "                                         description  \\\n",
       "0         Solve the Linear equation:            [2]    \n",
       "1       Solve the linear equation:            [-18]    \n",
       "2    Solve the linear equation:            [1/2] ...   \n",
       "3    If      , then      [1/5]. &nbsp;Please writ...   \n",
       "4  I'll say an addition or subtraction sentence. ...   \n",
       "\n",
       "                                                text  \n",
       "0        Solve Linear equation Solve Linear equation  \n",
       "1        Solve linear equation Solve linear equation  \n",
       "2  Solve linear equation Solve linear equation Pl...  \n",
       "3                  nbsp Please write answer fraction  \n",
       "4  Lesson say addition subtraction sentence say a...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = util.get_train_test([col[\"texts\"] for col in collections])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6332 2716\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data), len(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Gensim word2vec embeddings\n",
    "\n",
    "# def get_embeddings(text, word_embedding_dim):\n",
    "#     global language_model\n",
    "#     global device\n",
    "#     embeds = []\n",
    "#     for word in text:\n",
    "#         if word in language_model.wv.vocab:\n",
    "#             embeds.append(torch.tensor(language_model.wv[word], dtype = torch.float, device = device))\n",
    "#         else:\n",
    "#             embeds.append(torch.zeros(word_embedding_dim, device = device))\n",
    "#     return torch.cat(embeds).view(len(text),word_embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Glove embeddings\n",
    "\n",
    "def get_embeddings(text, word_embedding_dim):\n",
    "    global vocab\n",
    "    global device\n",
    "    embeds = []\n",
    "    for word in text:\n",
    "        if word in vocab:\n",
    "            embeds.append(torch.tensor(vocab[word], dtype = torch.float, device = device))\n",
    "        else:\n",
    "            embeds.append(torch.zeros(word_embedding_dim, device = device))\n",
    "    return torch.cat(embeds).view(len(text),word_embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining model\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim, word_hidden_dim, sent_hidden_dim, vocab_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.word_hidden_dim = word_hidden_dim\n",
    "        self.sent_hidden_dim = sent_hidden_dim\n",
    "#         self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.word_lstm = nn.LSTM(embedding_dim, word_hidden_dim)\n",
    "        self.sent_lstm = nn.LSTM(word_hidden_dim, sent_hidden_dim)\n",
    "        \n",
    "        self.hidden2out = nn.Linear(sent_hidden_dim, 2)\n",
    "        self.sent_hidden = self.init_sent_hidden()\n",
    "        \n",
    "    def init_word_hidden(self):\n",
    "        return (torch.zeros(1,1,self.word_hidden_dim, device = device), torch.zeros(1,1,self.word_hidden_dim, device = device))\n",
    "    \n",
    "    def init_sent_hidden(self):\n",
    "        return (torch.zeros(1,1,self.sent_hidden_dim, device = device), torch.zeros(1,1,self.sent_hidden_dim, device = device))\n",
    "\n",
    "    def forward(self, collection):\n",
    "        outputs = []\n",
    "        for i,word_embeds in enumerate(collection):\n",
    "#             print(\"word_ixs: \",word_ixs)\n",
    "            self.word_hidden = self.init_word_hidden()\n",
    "#             word_embeds = self.embeddings(word_ixs)\n",
    "            word_lstm_out, self.word_hidden = self.word_lstm(word_embeds.view(len(word_embeds),1,-1), self.word_hidden)\n",
    "            outputs.append(self.word_hidden[0])\n",
    "            \n",
    "        word_hiddens = torch.cat(outputs)\n",
    "        sent_lstm_out, self.sent_hidden = self.sent_lstm(word_hiddens, self.sent_hidden)\n",
    "#         print(\"Sent hidden, \",self.sent_hidden[0], self.sent_hidden[0].shape)\n",
    "        out = self.hidden2out(sent_lstm_out[-1])\n",
    "        score = F.log_softmax(out, dim = 1)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 0 percent complete\n",
      "Current accuracy:  0.0\n",
      "epoch  1 5 percent complete\n",
      "Current accuracy:  0.5188679245283019\n",
      "epoch  1 10 percent complete\n",
      "Current accuracy:  0.5669291338582677\n",
      "epoch  1 15 percent complete\n",
      "Current accuracy:  0.5688748685594112\n",
      "epoch  1 20 percent complete\n",
      "Current accuracy:  0.6096214511041009\n",
      "epoch  1 25 percent complete\n",
      "Current accuracy:  0.6477272727272727\n",
      "epoch  1 30 percent complete\n",
      "Current accuracy:  0.6917411888479748\n",
      "epoch  1 35 percent complete\n",
      "Current accuracy:  0.7168620378719567\n",
      "epoch  1 40 percent complete\n",
      "Current accuracy:  0.7438831886345698\n",
      "epoch  1 45 percent complete\n",
      "Current accuracy:  0.7362329007365837\n",
      "epoch  1 50 percent complete\n",
      "Current accuracy:  0.7527628670666245\n",
      "epoch  1 55 percent complete\n",
      "Current accuracy:  0.7680826636050516\n",
      "epoch  1 60 percent complete\n",
      "Current accuracy:  0.7774269928966061\n",
      "epoch  1 65 percent complete\n",
      "Current accuracy:  0.7908671362642701\n",
      "epoch  1 70 percent complete\n",
      "Current accuracy:  0.8022101939557961\n",
      "epoch  1 75 percent complete\n",
      "Current accuracy:  0.8117894736842105\n",
      "epoch  1 80 percent complete\n",
      "Current accuracy:  0.819617130451944\n",
      "epoch  1 85 percent complete\n",
      "Current accuracy:  0.8263372956909361\n",
      "epoch  1 90 percent complete\n",
      "Current accuracy:  0.8335087719298245\n",
      "epoch  1 95 percent complete\n",
      "Current accuracy:  0.840452052517866\n",
      "\n",
      "epoch 1 loss: 2302.94408634305\n",
      "\n",
      "epoch  2 0 percent complete\n",
      "Current accuracy:  0.0\n",
      "epoch  2 5 percent complete\n",
      "Current accuracy:  0.8867924528301887\n",
      "epoch  2 10 percent complete\n",
      "Current accuracy:  0.9228346456692913\n",
      "epoch  2 15 percent complete\n",
      "Current accuracy:  0.9263932702418507\n",
      "epoch  2 20 percent complete\n",
      "Current accuracy:  0.9329652996845426\n",
      "epoch  2 25 percent complete\n",
      "Current accuracy:  0.9116161616161617\n",
      "epoch  2 30 percent complete\n",
      "Current accuracy:  0.8979484481851657\n",
      "epoch  2 35 percent complete\n",
      "Current accuracy:  0.8800721370604148\n",
      "epoch  2 40 percent complete\n",
      "Current accuracy:  0.8756906077348067\n",
      "epoch  2 45 percent complete\n",
      "Current accuracy:  0.8716239915819011\n",
      "epoch  2 50 percent complete\n",
      "Current accuracy:  0.8692769182191348\n",
      "epoch  2 55 percent complete\n",
      "Current accuracy:  0.8699770378874856\n",
      "epoch  2 60 percent complete\n",
      "Current accuracy:  0.8718758221520653\n",
      "epoch  2 65 percent complete\n",
      "Current accuracy:  0.8758804955064368\n",
      "epoch  2 70 percent complete\n",
      "Current accuracy:  0.87595850248083\n",
      "epoch  2 75 percent complete\n",
      "Current accuracy:  0.8747368421052631\n",
      "epoch  2 80 percent complete\n",
      "Current accuracy:  0.8746792974146438\n",
      "epoch  2 85 percent complete\n",
      "Current accuracy:  0.8681277860326895\n",
      "epoch  2 90 percent complete\n",
      "Current accuracy:  0.8554385964912281\n",
      "epoch  2 95 percent complete\n",
      "Current accuracy:  0.8480970583347183\n",
      "\n",
      "epoch 2 loss: 2440.3665218651295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "model = LSTMClassifier(EMBEDDING_DIM, WORD_HIDDEN_DIM, SENT_HIDDEN_DIM, len(word_to_ix)).to(device)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
    "\n",
    "for epoch in range(2):\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    printed_percentages = []\n",
    "    corrects = 0\n",
    "    for collection,label in training_data:\n",
    "        \n",
    "        complete_percentage = int(count*100/len(training_data))\n",
    "        if complete_percentage%5 == 0 and (complete_percentage not in printed_percentages):\n",
    "            print(\"epoch \",epoch+1,complete_percentage,\"percent complete\")\n",
    "            print(\"Current accuracy: \",corrects/(count+1))\n",
    "            printed_percentages.append(complete_percentage)\n",
    "        count+=1\n",
    "        \n",
    "        label = torch.tensor([label], dtype = torch.long, device = device)\n",
    "#         collection_ixs = [prepare_sequence(text.split(),word_to_ix) for text in collection]\n",
    "        collection_embeds =[get_embeddings(text.split(), EMBEDDING_DIM) for text in collection]\n",
    "        model.zero_grad()\n",
    "\n",
    "        model.sent_hidden = model.init_sent_hidden()\n",
    "#         print(collection_ixs)\n",
    "        \n",
    "        score = model(collection_embeds)\n",
    "        \n",
    "        _, predicted = torch.max(score,1)\n",
    "        correct = 1 if (predicted == label) else 0\n",
    "        corrects += correct\n",
    "        \n",
    "#         print(score.shape,label.shape)\n",
    "        loss = loss_function(score, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.step()\n",
    "    print(\"\\nepoch \"+str(epoch+1)+\" loss: \"+str(total_loss)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  0\n",
      "Total collections : 2716\n",
      "Correct predictions: 1358\n",
      "Accuracy : 0.5\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "with torch.no_grad():\n",
    "    total_coll = len(testing_data)\n",
    "    correct_preds = 0\n",
    "    count = 0\n",
    "    for collection,label  in testing_data:\n",
    "        label = torch.tensor(label, dtype = torch.long, device = device)\n",
    "        collection_embeds =[get_embeddings(text.split(), EMBEDDING_DIM) for text in collection]\n",
    "#         collection_ixs = [prepare_sequence(text.split(),word_to_ix) for text in collection]\n",
    "        score = model(collection_embeds)\n",
    "        _, predicted = torch.max(score,1)\n",
    "        correct = 1 if (predicted == label) else 0\n",
    "        correct_preds += correct\n",
    "                \n",
    "    print(\"Count: \",count)\n",
    "    print(\"Total collections : \"+str(total_coll))\n",
    "    print(\"Correct predictions: \"+str(correct_preds))\n",
    "    print (\"Accuracy : \"+str(correct_preds/total_coll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model,\"./models/word_lstm_collections_csv.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
